import gym
import numpy as np
import jumpfrog
from stable_baselines.ddpg.policies import MlpPolicy
from stable_baselines.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise, AdaptiveParamNoiseSpec
from stable_baselines import DDPG,SAC
import time
import os
import matplotlib.pyplot as plt

from stable_baselines import DDPG
from stable_baselines import results_plotter
from stable_baselines.bench import Monitor
from stable_baselines.results_plotter import load_results, ts2xy
from stable_baselines.common.callbacks import BaseCallback

if __name__ == '__main__':
    env = gym.make('jumpfrog-v0')
    env.switchmode()
    model = SAC.load("tmp/best_model.zip")

    obs = env.reset()
    for i in range(10000):
        action, _states = model.predict(obs)
        obs, rewards, dones, info = env.step(action)
        # print("reward:",rewards)
        env.render()